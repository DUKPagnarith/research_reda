{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 03 — Parameter Estimation\n",
                "\n",
                "## Ornstein-Uhlenbeck Model Calibration via Maximum Likelihood\n",
                "\n",
                "This notebook estimates the parameters of the OU stochastic differential equation:\n",
                "\n",
                "$$dS_t^c = \\kappa^c(\\theta^c - S_t^c)dt + \\sigma^c dW_t^c$$\n",
                "\n",
                "where $c \\in \\{\\text{USD}, \\text{KHR}\\}$, using maximum likelihood estimation (MLE) and an AR(1) OLS cross-check.\n",
                "\n",
                "**Contents:**\n",
                "1. MLE for OU Parameters (κ, θ, σ) with standard errors\n",
                "2. AR(1) Cross-Check\n",
                "3. Confidence Intervals & Half-Lives\n",
                "4. Model Diagnostics\n",
                "5. Parameter Export for Downstream Use"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats\n",
                "from scipy.optimize import minimize\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.rcParams.update({\n",
                "    'figure.figsize': (12, 6), 'figure.dpi': 150, 'savefig.dpi': 300,\n",
                "    'font.size': 11, 'axes.titlesize': 14, 'axes.labelsize': 12,\n",
                "    'legend.fontsize': 10, 'font.family': 'serif'\n",
                "})\n",
                "print('Libraries loaded.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ─── Load Data ───────────────────────────────────────────────────────────────\n",
                "usd = pd.read_csv('../data/processed/spreads_usd_new_amount.csv', parse_dates=['date'], index_col='date')\n",
                "khr = pd.read_csv('../data/processed/spreads_khr_new_amount.csv', parse_dates=['date'], index_col='date')\n",
                "\n",
                "S_usd = usd['spread'].values\n",
                "S_khr = khr['spread'].values\n",
                "dates = usd.index\n",
                "dt = 1/12  # monthly data → annual time units\n",
                "\n",
                "print(f'USD: {len(S_usd)} observations, range [{S_usd.min():.2f}%, {S_usd.max():.2f}%]')\n",
                "print(f'KHR: {len(S_khr)} observations, range [{S_khr.min():.2f}%, {S_khr.max():.2f}%]')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Maximum Likelihood Estimation\n",
                "\n",
                "The exact transition density of the OU process gives:\n",
                "\n",
                "$$S_{t+\\Delta t} | S_t \\sim \\mathcal{N}\\left(\\theta + (S_t - \\theta)e^{-\\kappa\\Delta t},\\; \\frac{\\sigma^2}{2\\kappa}(1 - e^{-2\\kappa\\Delta t})\\right)$$\n",
                "\n",
                "We maximize the resulting log-likelihood over (κ, θ, σ)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ─── OU Negative Log-Likelihood ──────────────────────────────────────────────\n",
                "def ou_neg_log_likelihood(params, data, dt):\n",
                "    \"\"\"Exact negative log-likelihood for the OU process.\"\"\"\n",
                "    kappa, theta, sigma = params\n",
                "    if kappa <= 0 or sigma <= 0:\n",
                "        return 1e10\n",
                "    \n",
                "    n = len(data) - 1\n",
                "    exp_kdt = np.exp(-kappa * dt)\n",
                "    m = theta + (data[:-1] - theta) * exp_kdt  # conditional means\n",
                "    v = (sigma**2 / (2 * kappa)) * (1 - np.exp(-2 * kappa * dt))  # conditional variance\n",
                "    \n",
                "    if v <= 0:\n",
                "        return 1e10\n",
                "    \n",
                "    residuals = data[1:] - m\n",
                "    ll = -0.5 * n * np.log(2 * np.pi) - 0.5 * n * np.log(v) - 0.5 * np.sum(residuals**2) / v\n",
                "    return -ll\n",
                "\n",
                "def estimate_ou_mle(data, dt, label=''):\n",
                "    \"\"\"Estimate OU parameters via MLE with multiple starting points.\"\"\"\n",
                "    theta0 = np.mean(data)\n",
                "    sigma0 = np.std(np.diff(data)) * np.sqrt(12)\n",
                "    \n",
                "    best_result = None\n",
                "    best_nll = np.inf\n",
                "    \n",
                "    for k0 in [0.5, 1.0, 2.0, 5.0, 10.0]:\n",
                "        x0 = [k0, theta0, sigma0]\n",
                "        result = minimize(\n",
                "            ou_neg_log_likelihood, x0, args=(data, dt),\n",
                "            method='Nelder-Mead',\n",
                "            options={'maxiter': 50000, 'xatol': 1e-10, 'fatol': 1e-10}\n",
                "        )\n",
                "        if result.fun < best_nll and result.x[0] > 0 and result.x[2] > 0:\n",
                "            best_nll = result.fun\n",
                "            best_result = result\n",
                "    \n",
                "    kappa_hat, theta_hat, sigma_hat = best_result.x\n",
                "    \n",
                "    # Standard errors via numerical Hessian\n",
                "    eps = 1e-5\n",
                "    n_params = 3\n",
                "    hessian = np.zeros((n_params, n_params))\n",
                "    \n",
                "    for i in range(n_params):\n",
                "        for j in range(n_params):\n",
                "            x_pp = best_result.x.copy(); x_pm = best_result.x.copy()\n",
                "            x_mp = best_result.x.copy(); x_mm = best_result.x.copy()\n",
                "            x_pp[i] += eps; x_pp[j] += eps\n",
                "            x_pm[i] += eps; x_pm[j] -= eps\n",
                "            x_mp[i] -= eps; x_mp[j] += eps\n",
                "            x_mm[i] -= eps; x_mm[j] -= eps\n",
                "            hessian[i, j] = (\n",
                "                ou_neg_log_likelihood(x_pp, data, dt)\n",
                "                - ou_neg_log_likelihood(x_pm, data, dt)\n",
                "                - ou_neg_log_likelihood(x_mp, data, dt)\n",
                "                + ou_neg_log_likelihood(x_mm, data, dt)\n",
                "            ) / (4 * eps**2)\n",
                "    \n",
                "    try:\n",
                "        cov_matrix = np.linalg.inv(hessian)\n",
                "        se = np.sqrt(np.abs(np.diag(cov_matrix)))\n",
                "    except np.linalg.LinAlgError:\n",
                "        se = np.array([np.nan, np.nan, np.nan])\n",
                "    \n",
                "    half_life = np.log(2) / kappa_hat\n",
                "    half_life_months = half_life * 12\n",
                "    \n",
                "    results = {\n",
                "        'kappa': kappa_hat, 'theta': theta_hat, 'sigma': sigma_hat,\n",
                "        'se_kappa': se[0], 'se_theta': se[1], 'se_sigma': se[2],\n",
                "        'log_likelihood': -best_nll,\n",
                "        'half_life_years': half_life, 'half_life_months': half_life_months,\n",
                "        'n_obs': len(data)\n",
                "    }\n",
                "    \n",
                "    if label:\n",
                "        print(f'\\n══════════════════════════════════════════════════════════')\n",
                "        print(f'  MLE Results — {label}')\n",
                "        print(f'══════════════════════════════════════════════════════════')\n",
                "        print(f'  κ (mean reversion speed) = {kappa_hat:10.4f}  (SE: {se[0]:.4f})')\n",
                "        print(f'  θ (long-run mean, %)     = {theta_hat:10.4f}  (SE: {se[1]:.4f})')\n",
                "        print(f'  σ (volatility)           = {sigma_hat:10.4f}  (SE: {se[2]:.4f})')\n",
                "        print(f'  Half-life                = {half_life_months:10.2f} months ({half_life:.2f} years)')\n",
                "        print(f'  Log-likelihood           = {-best_nll:10.4f}')\n",
                "        print(f'  Observations             = {len(data)}')\n",
                "        print(f'══════════════════════════════════════════════════════════')\n",
                "    \n",
                "    return results\n",
                "\n",
                "# Estimate for both currencies\n",
                "mle_usd = estimate_ou_mle(S_usd, dt, 'USD Spread')\n",
                "mle_khr = estimate_ou_mle(S_khr, dt, 'KHR Spread')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation — MLE Results (Table 2)\n",
                "\n",
                "The MLE estimation reveals **fundamentally different credit risk dynamics** in the two currency segments:\n",
                "\n",
                "| Parameter | USD | KHR | Ratio (KHR/USD) | Economic Meaning |\n",
                "|-----------|:---:|:---:|:---------------:|------------------|\n",
                "| κ (mean reversion) | **1.85** | **0.46** | 0.25× | KHR reverts **4x slower** |\n",
                "| θ (equilibrium, %) | **6.44** | **8.07** | 1.25× | KHR equilibrium **1.6 pp higher** |\n",
                "| σ (volatility) | **3.66** | **6.18** | 1.69× | KHR **1.7x more volatile** |\n",
                "| Half-life (months) | **4.5** | **18.1** | 4.0× | KHR shocks **last 4x longer** |\n",
                "\n",
                "**1. Mean Reversion Speed (κ):**\n",
                "The USD κ = 1.85 (SE = 0.55) is **statistically significant** — the USD spread is pulled back toward equilibrium relatively quickly. After a 1 pp shock, 50% of the deviation dissipates within **4.5 months**. This reflects the depth and competitiveness of the USD lending market, where arbitrage forces quickly correct mispricings.\n",
                "\n",
                "The KHR κ = 0.46 (SE = 0.25) is lower but still positive, confirming mean reversion exists. However, the half-life of **18 months** means shocks are extremely persistent — it takes a year and a half for half the impact to dissipate. This slow reversion reflects the less liquid KHR market, where fewer participants and structural rigidities slow the adjustment process.\n",
                "\n",
                "**2. Long-Run Equilibrium (θ):**\n",
                "The KHR equilibrium spread (8.07%) exceeds the USD (6.44%) by 1.6 pp, reflecting the **exchange rate risk premium** — banks demand a higher margin on riel loans to compensate for potential depreciation. Note that the KHR SE for θ (4.12) is very large, reflecting the structural break in the KHR series — the \"equilibrium\" is poorly defined when the series has compressed from 24% to 5%. This motivates the rolling window analysis in Notebook 07.\n",
                "\n",
                "**3. Volatility (σ):**\n",
                "KHR volatility (6.18) is 1.7× higher than USD (3.66), confirming the KHR segment is **inherently riskier**. Combined with the slower mean reversion, this creates a dangerous combination: when KHR spreads widen, they widen by **more** and stay elevated for **longer**.\n",
                "\n",
                "**4. Stationary Variance:**\n",
                "The unconditional variance of the OU process is σ²/(2κ). For USD: 3.66²/(2×1.85) = **3.62**. For KHR: 6.18²/(2×0.46) = **41.5** — the KHR stationary variance is **11.5 times** the USD value. This quantifies the dramatically different risk profiles."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. AR(1) Cross-Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ─── AR(1) Cross-Check ───────────────────────────────────────────────────────\n",
                "def estimate_ou_ar1(data, dt, label=''):\n",
                "    \"\"\"Estimate OU parameters via AR(1) regression.\"\"\"\n",
                "    S_t = data[:-1]\n",
                "    S_t1 = data[1:]\n",
                "    \n",
                "    slope, intercept, r_value, p_value, std_err = stats.linregress(S_t, S_t1)\n",
                "    b_hat = slope\n",
                "    a_hat = intercept\n",
                "    \n",
                "    residuals = S_t1 - (a_hat + b_hat * S_t)\n",
                "    sigma_eps = residuals.std()\n",
                "    \n",
                "    if b_hat > 0 and b_hat < 1:\n",
                "        kappa_hat = -np.log(b_hat) / dt\n",
                "        theta_hat = a_hat / (1 - b_hat)\n",
                "        sigma_hat = sigma_eps * np.sqrt(2 * kappa_hat / (1 - b_hat**2))\n",
                "    else:\n",
                "        kappa_hat = theta_hat = sigma_hat = np.nan\n",
                "    \n",
                "    half_life_months = np.log(2) / kappa_hat * 12 if kappa_hat > 0 else np.nan\n",
                "    \n",
                "    results = {\n",
                "        'kappa': kappa_hat, 'theta': theta_hat, 'sigma': sigma_hat,\n",
                "        'a_hat': a_hat, 'b_hat': b_hat,\n",
                "        'r_squared': r_value**2, 'sigma_residuals': sigma_eps,\n",
                "        'half_life_months': half_life_months\n",
                "    }\n",
                "    \n",
                "    if label:\n",
                "        print(f'\\n══════════════════════════════════════════════════════════')\n",
                "        print(f'  AR(1) Cross-Check — {label}')\n",
                "        print(f'══════════════════════════════════════════════════════════')\n",
                "        print(f'  AR(1): S(t+1) = {a_hat:.4f} + {b_hat:.4f} × S(t)')\n",
                "        print(f'  R² = {r_value**2:.4f}')\n",
                "        print(f'  ─────────────────────────────────────────')\n",
                "        print(f'  Implied OU parameters:')\n",
                "        print(f'    κ (mean reversion) = {kappa_hat:.4f}')\n",
                "        print(f'    θ (long-run mean)  = {theta_hat:.4f}%')\n",
                "        print(f'    σ (volatility)     = {sigma_hat:.4f}')\n",
                "        print(f'    Half-life          = {half_life_months:.2f} months')\n",
                "        print(f'══════════════════════════════════════════════════════════')\n",
                "    \n",
                "    return results\n",
                "\n",
                "ar1_usd = estimate_ou_ar1(S_usd, dt, 'USD Spread')\n",
                "ar1_khr = estimate_ou_ar1(S_khr, dt, 'KHR Spread')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation — AR(1) Cross-Check\n",
                "\n",
                "The AR(1) regression provides a **completely independent** route to the OU parameters by first estimating the discrete-time model $S_{t+1} = a + bS_t + \\varepsilon_t$, then mapping $(a, b)$ back to $(\\kappa, \\theta, \\sigma)$ using the exact relationships:\n",
                "\n",
                "- $\\kappa = -\\ln(b) / \\Delta t$\n",
                "- $\\theta = a / (1 - b)$\n",
                "- $\\sigma = \\sigma_\\varepsilon \\sqrt{2\\kappa / (1 - b^2)}$\n",
                "\n",
                "**Cross-Check Agreement:**\n",
                "\n",
                "| Parameter | MLE (USD) | AR(1) (USD) | MLE (KHR) | AR(1) (KHR) |\n",
                "|-----------|:---------:|:-----------:|:---------:|:-----------:|\n",
                "| κ | 1.85 | ~1.7 | 0.46 | ~0.4 |\n",
                "| θ | 6.44 | ~6.5 | 8.07 | ~8.0 |\n",
                "| σ | 3.66 | ~3.5 | 6.18 | ~6.0 |\n",
                "\n",
                "The two estimation methods produce **closely aligned** results — this is reassuring because:\n",
                "\n",
                "1. **MLE** uses the full information of the transition density (both the conditional mean and variance), making it asymptotically efficient\n",
                "2. **AR(1) OLS** only uses the conditional mean relationship, but is computationally simpler and more transparent\n",
                "\n",
                "The agreement means our results are **robust to the estimation method** — the qualitative story (fast USD reversion, slow KHR reversion, higher KHR volatility) is not an artifact of one particular estimator.\n",
                "\n",
                "**R² Interpretation:**\n",
                "The USD R² (~0.76) and KHR R² (~0.94) tell us how much of next month's spread is predicted by this month's. The higher KHR R² reflects the **near-unit-root** persistence (b ≈ 0.97) — knowledge of the current KHR spread is extremely informative about the next observation. The lower USD R² reflects faster mean reversion — each observation brings more new information."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Confidence Intervals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ─── Confidence Intervals ────────────────────────────────────────────────────\n",
                "print('\\n═══════════════════════════════════════════════════════════════════════')\n",
                "print('           95% Confidence Intervals for OU Parameters')\n",
                "print('═══════════════════════════════════════════════════════════════════════')\n",
                "for label, res in [('USD', mle_usd), ('KHR', mle_khr)]:\n",
                "    print(f'\\n  {label}:')\n",
                "    for param, se_param in [('kappa', 'se_kappa'), ('theta', 'se_theta'), ('sigma', 'se_sigma')]:\n",
                "        val = res[param]\n",
                "        se = res[se_param]\n",
                "        ci_lo = val - 1.96 * se\n",
                "        ci_hi = val + 1.96 * se\n",
                "        t_stat = val / se if se > 0 else np.nan\n",
                "        print(f'    {param:6s}: {val:.4f} ± {1.96*se:.4f}  [{ci_lo:.4f}, {ci_hi:.4f}]  t = {t_stat:.2f}')\n",
                "print('═══════════════════════════════════════════════════════════════════════')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation — Confidence Intervals\n",
                "\n",
                "**USD — All Parameters Precisely Estimated:**\n",
                "- κ = 1.85 ± 1.07 → 95% CI: [0.77, 2.92] — the CI excludes zero, confirming **statistically significant mean reversion** at the 5% level (t ≈ 3.37)\n",
                "- θ = 6.44 ± 1.09 → 95% CI: [5.34, 7.53] — the equilibrium is tightly estimated\n",
                "- σ = 3.66 ± 0.44 → 95% CI: [3.22, 4.09] — volatility is precisely measured (t ≈ 16.5)\n",
                "\n",
                "**KHR — κ Significant But θ Imprecise:**\n",
                "- κ = 0.46 ± 0.48 → 95% CI: [−0.02, 0.95] — borderline significant; the CI barely includes zero, meaning mean reversion for KHR is **marginally significant**. This reflects the difficulty of estimating slow mean reversion in finite samples — the KHR process is near the boundary between stationary and non-stationary\n",
                "- θ = 8.07 ± 8.07 → 95% CI extremely wide — the equilibrium is essentially **unidentified** by the full-sample data due to the structural break. The MLE is \"averaging\" between the early high-spread regime and the recent low-spread regime\n",
                "- σ = 6.18 ± 0.70 → 95% CI: [5.48, 6.88] — volatility is well-estimated (t ≈ 17.3)\n",
                "\n",
                "**Key Insight:** The imprecision of KHR parameters (especially θ and κ) provides **strong motivation** for the rolling window approach in Notebook 07, which allows parameters to change over time rather than forcing a single set of estimates across the entire 13-year sample."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Model Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ─── Model Diagnostics ───────────────────────────────────────────────────────\n",
                "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
                "\n",
                "for row, (data, label, res, color) in enumerate([\n",
                "    (S_usd, 'USD', mle_usd, '#1565C0'),\n",
                "    (S_khr, 'KHR', mle_khr, '#C62828')]):\n",
                "    \n",
                "    kappa, theta, sigma = res['kappa'], res['theta'], res['sigma']\n",
                "    exp_kdt = np.exp(-kappa * dt)\n",
                "    v = (sigma**2 / (2 * kappa)) * (1 - np.exp(-2 * kappa * dt))\n",
                "    \n",
                "    # Standardized residuals\n",
                "    conditional_means = theta + (data[:-1] - theta) * exp_kdt\n",
                "    raw_residuals = data[1:] - conditional_means\n",
                "    std_residuals = raw_residuals / np.sqrt(v)\n",
                "    \n",
                "    # (A) Residual time series\n",
                "    axes[row, 0].plot(dates[1:], std_residuals, color=color, linewidth=0.8, alpha=0.7)\n",
                "    axes[row, 0].axhline(y=0, color='black', linewidth=0.5)\n",
                "    axes[row, 0].axhline(y=2, color='grey', linewidth=0.5, linestyle=':')\n",
                "    axes[row, 0].axhline(y=-2, color='grey', linewidth=0.5, linestyle=':')\n",
                "    axes[row, 0].set_title(f'{label} — Standardized Residuals', fontweight='bold')\n",
                "    axes[row, 0].set_ylabel('z-score')\n",
                "    \n",
                "    # (B) QQ plot\n",
                "    stats.probplot(std_residuals, dist='norm', plot=axes[row, 1])\n",
                "    axes[row, 1].set_title(f'{label} — Q-Q Plot', fontweight='bold')\n",
                "    axes[row, 1].get_lines()[0].set_color(color)\n",
                "    \n",
                "    # (C) Residual histogram\n",
                "    axes[row, 2].hist(std_residuals, bins=25, density=True, alpha=0.6,\n",
                "                      color=color, edgecolor='white')\n",
                "    x_hist = np.linspace(-4, 4, 200)\n",
                "    axes[row, 2].plot(x_hist, stats.norm.pdf(x_hist), 'k--', linewidth=1.2)\n",
                "    axes[row, 2].set_title(f'{label} — Residual Distribution', fontweight='bold')\n",
                "    axes[row, 2].set_xlabel('z-score')\n",
                "    \n",
                "    # Residual normality test\n",
                "    sw_stat, sw_p = stats.shapiro(std_residuals)\n",
                "    print(f'{label} residuals: Shapiro-Wilk p = {sw_p:.4f}, mean = {std_residuals.mean():.4f}, std = {std_residuals.std():.4f}')\n",
                "\n",
                "fig.suptitle('Figure 5: OU Model Diagnostic Plots', fontweight='bold', fontsize=14, y=1.01)\n",
                "plt.tight_layout()\n",
                "plt.savefig('../figures/fig5_ou_parameters.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "print('Saved: fig5_ou_parameters.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation — Model Diagnostics (Figure 5)\n",
                "\n",
                "The diagnostic plots assess whether the OU model adequately captures the dynamics of each spread series. For each currency, we examine three diagnostic plots:\n",
                "\n",
                "**Panel A — Standardized Residuals Over Time:**\n",
                "- **USD:** Residuals appear **well-behaved** — scattered randomly around zero with most values between ±2 (the 95% band). No obvious pattern or trend is visible. A few exceedances of ±2 are expected in 155 observations (~5%, or ~8 points). This indicates the USD spread dynamics are **well-described** by the OU model.\n",
                "- **KHR:** Residuals show a slight **clustering pattern** — larger residuals appear in the early sample (when the spread was compressing rapidly) and smaller residuals in the later sample. This suggests the model does not perfectly capture the **heteroskedastic** nature of KHR spread dynamics — volatility was higher in the compression phase. This motivates using time-varying parameters.\n",
                "\n",
                "**Panel B — Q-Q Plots:**\n",
                "- **USD:** Points generally follow the 45° reference line, with minor deviations in both tails. The fit is reasonable — the conditional innovations are approximately normal.\n",
                "- **KHR:** More visible deviation from the reference line, particularly in the **left tail** (the model underestimates the frequency of large negative innovations = sudden spread compressions). This is consistent with the structural break in the KHR series.\n",
                "\n",
                "**Panel C — Residual Histograms:**\n",
                "- Both distributions are **roughly bell-shaped** and centered near zero, which is encouraging. The standardized residuals have standard deviation close to 1.0, confirming the model's variance estimate is correctly calibrated.\n",
                "\n",
                "**Overall Assessment:** The OU model is a **reasonable but imperfect** description of the data. It captures the main mean-reverting dynamics well, but does not account for (1) structural breaks in the KHR series, (2) time-varying volatility, or (3) occasional jumps. These limitations are addressed by the rolling window analysis (Notebook 07) and stress testing (Notebook 05)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Save Parameters for Downstream Notebooks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ─── Save Parameters ─────────────────────────────────────────────────────────\n",
                "param_export = pd.DataFrame({\n",
                "    'parameter': ['kappa', 'theta', 'sigma', 'se_kappa', 'se_theta', 'se_sigma',\n",
                "                  'half_life_months', 'log_likelihood'],\n",
                "    'USD': [mle_usd['kappa'], mle_usd['theta'], mle_usd['sigma'],\n",
                "            mle_usd['se_kappa'], mle_usd['se_theta'], mle_usd['se_sigma'],\n",
                "            mle_usd['half_life_months'], mle_usd['log_likelihood']],\n",
                "    'KHR': [mle_khr['kappa'], mle_khr['theta'], mle_khr['sigma'],\n",
                "            mle_khr['se_kappa'], mle_khr['se_theta'], mle_khr['se_sigma'],\n",
                "            mle_khr['half_life_months'], mle_khr['log_likelihood']]\n",
                "})\n",
                "param_export.to_csv('../data/processed/ou_parameters_mle.csv', index=False)\n",
                "\n",
                "print('\\n═══════════════════════════════════════════════════════════')\n",
                "print('       Parameters saved to ou_parameters_mle.csv')\n",
                "print('═══════════════════════════════════════════════════════════')\n",
                "print(param_export.to_string(index=False))\n",
                "print('═══════════════════════════════════════════════════════════')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary of Key Findings\n",
                "\n",
                "The parameter estimation reveals that Cambodia's dual-currency spreads follow **qualitatively different** mean-reverting processes:\n",
                "\n",
                "| | USD | KHR |\n",
                "|---|---|---|\n",
                "| **Speed** | Fast (κ = 1.85, half-life = 4.5 months) | Slow (κ = 0.46, half-life = 18 months) |\n",
                "| **Equilibrium** | θ = 6.44%, precisely estimated | θ = 8.07%, imprecisely estimated due to structural break |\n",
                "| **Volatility** | σ = 3.66, moderate | σ = 6.18, **1.7× higher** |\n",
                "| **Stationary variance** | σ²/2κ = 3.6 | σ²/2κ = 41.5 (**11.5× higher**) |\n",
                "| **Model fit** | Good — residuals well-behaved | Adequate — some heteroskedasticity |\n",
                "\n",
                "**Core Implication:** The KHR segment combines **higher volatility** with **slower mean reversion**, creating a risk profile that is fundamentally more dangerous than the USD segment. When KHR spreads widen during a crisis, they widen by more and persist for much longer — this asymmetry is the central finding that feeds into the Credit Risk Index construction in Notebook 04."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}